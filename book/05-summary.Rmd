# Data Summaries {#summary}

## Intended Learning Outcomes {#ilo-summary}

* Summarise data by groups
* Produce well-formatted tables

```{r setup-summary, message=FALSE}
library(tidyverse)   # data wrangling functions
library(rtweet) # for searching tweets
library(kableExtra)  # for nice tables
library(glue) # for pasting strings
```


## Summary functions

We'll use the `search_tweets()` function from `r pkg("rtweet")` to find the last (up to) 30K tweets from the past 6-9 days (this depends on Twitter) with the hashtag #NationalComingOutDay.

```{r, eval = FALSE}
tweets <- search_tweets(q = "#NationalComingOutDay", 
                        n = 30000, 
                        include_rts = FALSE)
# saveRDS(tweets, file = "data/ncod_tweets.rds")
```

This is mainly interesting around October 11th, so we've provided the relevant data for you that we scraped then, although you can follow along with any hashtag that interests you. 

```{r}
tweets <- readRDS("data/ncod_tweets.rds")
```

First, run `glimpse(tweets)` to find out what information is in the downloaded data. Now let's create a series of summary tables and plots with these data.

### Summarise

The `summarise()` function creates summary statistics for the data table. Check the [Data Transformation Cheat Sheet](https://raw.githubusercontent.com/rstudio/cheatsheets/main/data-transformation.pdf) for various summary functions. Some common ones are: `n()`, `min()`, `max()`, `sum()`, `mean()`, and `quantile()`.

This function can be used to answer questions like: How many tweets were there? What date range is represented in these data? What are the mean and median number of favourites per tweet?

The `n()` function counts the number of rows in the data. The `created_at` column gives us the date each tweet were created, so we can use the `min()` and `max()` functions to get the range of dates. The `favorite_count` column gives us the number of times each tweet was favourited.

```{r}
tweet_summary <- tweets %>%
  summarise(
    n = n(),
    min_date = min(created_at),
    max_date = max(created_at),
    avg_favs = mean(favorite_count),
    median_favs = quantile(favorite_count, .5)
  )

glimpse(tweet_summary)
```

::: {.info data-latex=""}
`r glossary("quantile", "Quantiles")` are like percentiles. Use `quantile(x, .50)` to find the median (the number where 50% of values in `x` are above it and 50% are below it). This can be useful when you need a value like "90% of tweets get *X* favourites or fewer".

```{r}
quantile(tweets$favorite_count, 0.90)
```

:::

There are a few ways to insert those values into the text of a report. First, you can use `glue()` to create a block of text that uses the objects you just created. Use the `format()` function to format the dates for our report.

```{r}
date_from <- tweet_summary$min_date %>% format("%d %B, %Y")
date_to <- tweet_summary$max_date %>% format("%d %B, %Y")

text <- glue("There were {tweet_summary$n} tweets between {date_from} and {date_to}.")
```

Then you can display that text in an `r glossary("R Markdown")` report with inline r like this, `r backtick("r text")`, which will produce the following:

> `r text`

Or you can insert individual objects into markdown text with inline r:

There were `r backtick("r tweet_summary$n")` tweets between `r backtick("r date_from")` and `r backtick("r date_to")`.

```{r, echo=FALSE}
mcq1 <- c(answer = "`tweets %>% summarise(max_retweets = max(retweets))`",
          x = "`tweets %>% summarise(max = retweets)`",
          x = "`tweets %>% summarise(max_retweets)`", 
          x = "`tweets %>% max(retweets)`") %>%
  sample() %>% longmcq()

mcq2 <- c(answer = "`summarise(width = mean(display_text_width))`",
          x = "`width(mean(display_text_width))`",
          x = "`summarise(display_text_width = mean)`",
          x = "`group_by(display_text_width)`") %>%
  sample() %>% longmcq()
```


::: {.try data-latex=""}
* How would you find the largest number of retweets?
    `r mcq1`
* How would you calculate the mean `display_text_width`? 
    `r mcq2`
:::

### Counting

How many different accounts tweeted? Who tweeted most?

You can count categories with the `count()` function. Since each row is a tweet, you can count the number of rows per `screen_name` to get the number of tweets per user. This will give you a new table with each combination of the counted columns and a column called `n` containing the number of observations from that group. Set `sort = TRUE` to sort the table by `n` in descending order.

```{r}
tweets_per_user <- tweets %>%
  count(screen_name, sort = TRUE)

head(tweets_per_user)
```

If you set a code chunk option to `results='asis'`, you can pipe the glued text to `cat()` to display it.

```{r, results='asis'}
unique_users <- nrow(tweets_per_user)
most_prolific <- slice(tweets_per_user, 1) %>% pull(screen_name)
most_prolific_n <- slice(tweets_per_user, 1) %>% pull(n)

glue("There were {unique_users} unique accounts 
     tweeting about #NationalComingOutDay. 
     {most_prolific} was the most prolific tweeter, 
     with {most_prolific_n} tweets.") %>% cat()
```


```{r, echo = FALSE}
mcq1 <- c(answer = "`tweets %>% count(is_quote, is_retweet)`", 
          x = "`tweets %>% count(is_quote) %>% count(is_retweet)`", 
          x = "`tweets %>% count(c(is_quote, is_retweet))`", 
          x = "`tweets %>% select(is_quote, is_retweet) %>% count()`") %>%
  sample() %>% longmcq()
```

::: {.try data-latex=""}
* How would you count the number of tweets that are quotes or not and are retweets or not? 
    `r mcq1`
:::

### Grouping

You can also create other summary values by group. 

The `lang` column tells us what language the tweet was in. How did the average number of favourites and retweets differ by language?

```{r}
lang <- tweets %>%
  group_by(lang) %>%
  summarise(count = n(),
            mean_favs = mean(favorite_count),
            mean_retweets = mean(retweet_count)) %>%
  ungroup() %>%
  arrange(desc(mean_favs))

head(lang)
```

::: {.warning data-latex=""}
If you get the following message, please update tidyverse.

> `summarise()` ungrouping output (override with `.groups` argument)
:::


```{r, echo = FALSE}
mcq3 <- c(answer = "`group_by(screen_name)`",
          x = "`summarise(screen_name)`",
          x = "`count(screen_name)`",
          x = "`mean(screen_name)`") %>%
  sample() %>% longmcq()
```


::: {.try data-latex=""}
* What would you change to calculate the mean favourites and retweets by `screen_name` instead of by `source`? 
    `r mcq3`
:::

You can use functions like `filter()` or `mutate()` after `group_by`. 



### Filtering

What was the most favourited original and quoted tweet? Group by `is_quote` and use `filter()` to keep just the rows where the value in the `favorite_count` column is equal to its maximum value. Just in case there was a tie, choose a random one with `sample_n(size = 1)`.

```{r}
most_fav <- tweets %>%
  group_by(is_quote) %>%
  filter(favorite_count == max(favorite_count)) %>%
  sample_n(size = 1) %>%
  ungroup()
```

::: {.warning data-latex=""}
Make sure you call the `ungroup()` function when you are done with grouped functions. Failing to do this can cause all sorts of mysterious problems if you use that data table later assuming it isn't grouped.
:::

Remember that you can access the value in each column with the `$` operator. 

```{r, results='asis'}
orig <- filter(most_fav, !is_quote)

glue("
The most favourited ({orig$favorite_count}) original tweet was by 
[{orig$screen_name}]({orig$status_url}):

--------------------------------------------------
{orig$text}

![]({orig$ext_media_url}){{width='100%'}}
--------------------------------------------------
") %>% 
  # prints results into document, not as code
  cat()
```

```{r, results='asis'}
quote <- filter(most_fav, is_quote)

glue("
The most favourited ({quote$favorite_count}) quote tweet was by 
[{quote$screen_name}]({quote$status_url}):

--------------------------------------------------
{quote$text}
--------------------------------------------------
") %>% 
  # prints results into document, not as code
  cat()
```


```{r, echo = FALSE}
mcq1 <- c(answer = "`tweets %>% group_by(source) %>% filter(n() >= 10)`", 
          x = "`tweets %>% group_by(source) %>% select(n() >= 10)`", 
          x = "`tweets %>% group_by(source) %>% filter(count() >= 10)`", 
          x = "`tweets %>% group_by(source) %>% select(count() >= 10)`") %>%
  sample() %>% longmcq()
```

::: {.try data-latex=""}
* How would you limit the results to sources with 10 or more rows?
    `r mcq1`
:::


## Putting it together {#together-summary}

Let's make a table of the top five hashtags used in conjunction with #NationalComingOutDay, the total number of tweets in each hashtag, the total number of likes, and the top tweet for each hashtag.

First, select just the relevant columns and expand the `hashtags` column. This is a column of lists, so you can create a row for each value using `unnest()`.

```{r}
tweets_with_hashtags <- tweets %>%
  select(hashtags, text, favorite_count, media_url) %>%
  unnest(cols = hashtags)
```

Now, count the number of tweets for each hashtag using `count()`, then get the top five values using `slice_max()` and ordering by the `n` column.

```{r}
top5_hashtags <- tweets_with_hashtags %>%
  count(hashtags) %>%
  filter(!is.na(hashtags)) %>%  # get rid of the blank value
  slice_max(order_by = n, n = 5)

top5_hashtags
```

Two of the hashtags are the same, but with different case. We can fix this by grouping by the lowercase version of the hashtag instead, using the `tolower()` function.

```{r}
top5_hashtags <- tweets_with_hashtags %>%
  count(hashtags = tolower(hashtags)) %>%
  filter(!is.na(hashtags)) %>%  # get rid of the blank value
  slice_max(order_by = n, n = 5)

top5_hashtags
```


Next, get the top tweet for each hashtag using `filter()`. Use `group_by()` before you filter to select the most-liked tweet in each hashtag, rather than the one with most likes overall. Don't forget to group by the lowercase version and `ungroup()` when you're done.

```{r}
top_tweet_per_hashtag <- tweets_with_hashtags %>%
  group_by(hashtags = tolower(hashtags)) %>%
  filter(favorite_count == max(favorite_count)) %>%
  sample_n(size = 1) %>%
  ungroup()
```

Get the total number of likes per hashtag by grouping and summarising with `sum()`.

```{r}
likes_per_hashtag <- tweets_with_hashtags %>%
  group_by(hashtags = tolower(hashtags)) %>%
  summarise(total_likes = sum(favorite_count)) %>%
  ungroup()
```


Finally, put everything together using `left_join()`, `select()` the columns you want to keep in the right order, and print the table.

```{r}
top5 <- top5_hashtags %>%
  left_join(top_tweet_per_hashtag, by = "hashtags") %>%
  left_join(likes_per_hashtag, by = "hashtags") %>%
  # replace @ with \@ so @ doesn't trigger referencing
  mutate(text = gsub("@", "\\\\@", text)) %>%
  # media_url can be a list if there is more than one image
  mutate(image = unlist(media_url)) %>%
  # put the columns you want to display in order
  select(hashtags, n, total_likes, text, image)

top5
```

The table isn't great, aesthetically. The `r pkg("kableExtra")` package has functions that will improve the presentation of tables. First, we'll combine the first three columns into a single column and add some `r glossary("HTML")` formatting to make the hashtag bold (`<strong>`) and insert line breaks (`<br>`). We'll also change the image column to display the image using html if there is an image.

```{r}
top5 %>%
  mutate(col1 = glue("<strong>#{hashtags}</strong>
                     <br>
                     tweets: {n}
                     <br>
                     likes: {total_likes}"),
         img = ifelse(!is.na(image),
                      glue("<img src='{image}' width='200px' />"),
                      "")) %>%
  select(col1, text, img) %>%
  kable(
    escape = FALSE, # allows HTML in the table
    col.names = c("Hashtag", "Top Tweet", ""),
    caption = "Stats and the top tweet for the top five hashtags.") %>%
  column_spec(1:2, extra_css = "vertical-align: top;") %>%
  row_spec(0, extra_css = "vertical-align: bottom;") %>%
  kable_paper()
```

## Glossary {#glossary-summary}

`r glossary_table()`

## Further resources {#resources-summary}

* [Data transformation cheat sheet](https://raw.githubusercontent.com/rstudio/cheatsheets/main/data-transformation.pdf)
* [Chapter 5: Data Transformation ](http://r4ds.had.co.nz/transform.html) in *R for Data Science*
