[{"path":"index.html","id":"overview","chapter":"Overview","heading":"Overview","text":"book provides overview basic skills needed turn raw data informative summaries visualisations presented professional reports presentations. book introduce learners R (R Core Team, 2021), programming language can help automate working data. book cover importing processing data spreadsheets, producing data summaries descriptive statistics tables, creating beautiful informative visualisations, constructing reports presentations automatically update underlying data changes.end book, able use R :clean process datasummarise datainformatively visualise datacreate reusable report templates","code":""},{"path":"index.html","id":"structure-of-the-course","chapter":"Overview","heading":"0.1 Structure of the course","text":"book accompanies 10-week course, covering one chapter per week. chapter introduce new skills concepts using concrete examples. various points, multiple-choice fill---blank questions check understanding. chapter accompanying walk-videos, instructor demonstrates skills covered chapter. chapter also accompanying exercises reinforce learning.","code":""},{"path":"index.html","id":"how-to-learn-data-skills","chapter":"Overview","heading":"0.2 How to learn data skills","text":"Learning data skills kind like gym membership (thanks Phil McAleer analogy). given state---art equipment use instructions use , data skills get stronger unless practice.Data skills require memorise lots code. introduced many different functions, main skill learn efficiently find information need. require getting used structure help files cheat sheets, learning Goggle problem choose helpful solution, learning read error messages.Learning code involves making lot mistakes. mistakes completely essential process, try feel frustrated. Many chapter exercises give broken code fix get experience seeing common errors look like. become experienced coder, might make fewer errors, recover much faster.","code":""},{"path":"wrangle.html","id":"wrangle","chapter":"1 Data Wrangling","heading":"1 Data Wrangling","text":"","code":""},{"path":"wrangle.html","id":"ilo-wrangle","chapter":"1 Data Wrangling","heading":"1.1 Intended Learning Outcomes","text":"able select filter data relevanceBe able create new columns edit existing onesBe able handle missing data","code":""},{"path":"wrangle.html","id":"set-up","chapter":"1 Data Wrangling","heading":"1.2 Set-up","text":"First, create new project work chapter named 08-wrangle. Second, open save new R Markdown document named wrangle.Rmd, delete welcome text load required packages chapter.need make folder called \"data\" download data file :\nbudget.csv.Download Data transformation cheat sheet.","code":"\nlibrary(tidyverse)   # data wrangling functions"},{"path":"wrangle.html","id":"wrangling-functions","chapter":"1 Data Wrangling","heading":"1.3 Wrangling functions","text":"Data wrangling refers process cleaning, transforming, restructuring data get format need analysis something spend awful lot time . data wrangling involves reshaping functions learned Chapter ?? six functions dplyr package loaded part tidyverse: select, filter, arrange, mutate, summarise, group_by. remember last two Chapter ??, cover briefly.worth highlighting chapter going cover common functions common uses said functions. However, dplyr (packages beyond ) huge number additional wrangling functions function many different arguments. Essentially, think able wrangle data particular way explicitly shown , almost certainly can, might just take bit Googling find .use small example table sales, expenses, satisfaction two years four regions two products. load data, use glimpse(budget) View(budget) get familiar data.","code":"\nbudget <- read_csv(\"data/budget.csv\", show_col_types = FALSE)"},{"path":"wrangle.html","id":"select","chapter":"1 Data Wrangling","heading":"1.3.1 Select","text":"can select subset columns (variables) table make easier view prepare table display. can also select columns new order.","code":""},{"path":"wrangle.html","id":"by-name-or-index","chapter":"1 Data Wrangling","heading":"1.3.1.1 By name or index","text":"can select columns name number (sometimes referred column index). Selecting number can useful column names long complicated.can select column individually, separated commas (e.g., region, sales_2019) can also select columns one another separating colon (e.g., sales_2019:expenses_2020).colon notation can much faster need type individual variable name, make sure know order columns always check output make sure selected intended.can rename columns time selecting setting new_name = old_col.","code":"\n# select single column by name\nproduct_dat <- budget %>% select(product) \n\n# select single column by number\nproduct_dat <- budget %>% select(2) \n# select columns individually\nsales2019 <- budget %>% select(region, product, sales_2019)\n\n# select columns with colon\nsales2019 <- budget %>% select(region:sales_2019)\nregions <- budget %>% select(`Sales Region` = 1, 3:6)\n\nhead(regions, 2)"},{"path":"wrangle.html","id":"un-selecting-columns","chapter":"1 Data Wrangling","heading":"1.3.1.2 Un-selecting columns","text":"can select columns either telling R ones want keep previous examples, specifying ones want exclude using minus symbol un-select columns. can also use colon notation de-select columns, need put parentheses around span first, e.g., -(sales_2019:expenses_2020), -sales_2019:expenses_2020.","code":"\n# de-select individual columns\nsales <- budget %>% select(-expenses_2019, -expenses_2020)\n\n# de-select a range of columns\nsales <- budget %>% select(-(expenses_2019:expenses_2020))"},{"path":"wrangle.html","id":"select-helpers","chapter":"1 Data Wrangling","heading":"1.3.1.3 Select helpers","text":"Finally, can select columns based criteria column names.resulting columns four examples?budget %>% select(contains(\"_\"))\n\nsales_2019, sales_2020sales_2020, expenses_2020, satisfaction_2020sales_2019, sales_2020, expenses_2019, expenses_2020, satisfaction_2019, satisfaction_2020expenses_2019, expenses_2020\nbudget %>% select(num_range(\"expenses_\", 2019:2020))\n\nsales_2019, sales_2020sales_2020, expenses_2020, satisfaction_2020sales_2019, sales_2020, expenses_2019, expenses_2020, satisfaction_2019, satisfaction_2020expenses_2019, expenses_2020\nbudget %>% select(starts_with(\"sales\"))\n\nsales_2019, sales_2020sales_2020, expenses_2020, satisfaction_2020sales_2019, sales_2020, expenses_2019, expenses_2020, satisfaction_2019, satisfaction_2020expenses_2019, expenses_2020\nbudget %>% select(ends_with(\"2020\"))\n\nsales_2019, sales_2020sales_2020, expenses_2020, satisfaction_2020sales_2019, sales_2020, expenses_2019, expenses_2020, satisfaction_2019, satisfaction_2020expenses_2019, expenses_2020\n","code":""},{"path":"wrangle.html","id":"filter","chapter":"1 Data Wrangling","heading":"1.3.2 Filter","text":"Whilst select() chooses columns want retain, filter() chooses rows retain matching row column criteria.can filter single criterion. criterion can rows certain column's value matches character value (e.g., \"North\") number (e.g., 9003). can also result logical equation (e.g., keep rows specific column value larger certain value). criterion checked row, result FALSE, row removed. can reverse equations specifying != ! means \"\".Remember use == = check two things equivalent. single = assigns right-hand value left-hand variable (much like <- operator).IDs kept table ?demo %>% filter(score < 80)\n1, 2233, 4demo %>% filter(grade == \"\")\n1, 2233, 4demo %>% filter(grade != \"\")\n1, 2233, 4demo %>% filter(score == 91)\n1, 2233, 4You can also select multiple criteria separating commas (rows kept match criteria). Additionally, can use & (\"\") | (\"\") create complex criteria.want filter retain multiple specific values variable, match operator (%%) used rather | (). ! can also used combination , placed variable name.Finally, can also pass many functions filter. example, package stringr loaded part tidyverse contains many different functions working strings (character data). example, use str_detect() retain rows customer satisfaction rating includes word \"high\"Note str_detect() case sensitive return values \"High\" \"HIGH\". can use function tolower() toupper() convert string lowercase uppercase search substring need case-insensitive matching.filter() incredibly powerful can allow select specific subsets data. , also quite dangerous start combining multiple criteria operators, easy accidentally specify something slightly different intended. Always check output. small dataset, can eyeball see looks right. larger dataset, may wish compute summary statistics count number groups/observations variable verify filter correct. level expertise coding can substitute knowing checking data.","code":"\n# select all rows where region equals North\nbudget %>% filter(region == \"North\")\n\n# select all rows where expenses_2020 were exactly equal to 200\nbudget %>% filter(expenses_2020 == 200)\n\n# select all rows where sales_2019 was more than 100\nbudget %>% filter(sales_2019 > 100)\n\n# everything but the North\nbudget %>% filter(region != \"North\")\n# regions and products with profit in both 2019 and 2020\nprofit_both <- budget %>% \n  filter(\n    sales_2019 > expenses_2019,\n    sales_2020 > expenses_2020\n  )\n\n# the same as above, using & instead of a comma\nprofit_both <- budget %>% \n  filter(\n    sales_2019 > expenses_2019 &\n    sales_2020 > expenses_2020\n  )\n\n# regions and products with profit in 2019 or 2020\nprofit_either <- budget %>% \n  filter(\n    sales_2019 > expenses_2019 |\n    sales_2020 > expenses_2020\n  )\n\n# 2020 profit greater than 1000\nprofit_1000 <- budget %>%\n  filter(sales_2020 - expenses_2020 > 1000)\n# retain any rows where region is north or south, and where product equals widget\nbudget %>%\n  filter(region %in% c(\"North\", \"South\"),\n         product == \"widgets\")\n\n# retain any rows where the region is not east or west, and where the product does not equal gadgets\nbudget %>%\n  filter(!region %in% c(\"East\", \"West\"),\n         product != \"gadgets\")\nbudget %>%\n  filter(str_detect(satisfaction_2019, \"high\"))"},{"path":"wrangle.html","id":"arrange","chapter":"1 Data Wrangling","heading":"1.3.3 Arrange","text":"can sort dataset using arrange(). find needing sort data R much less Excel, since need rows next order , example, calculate group means. arrange() can useful preparing data display tables. arrange() works character data sort alphabetically, well numeric data default ascending order (smallest largest). Reverse order using desc().want sort character data/categories specific order, turn column factor set levels desired order.","code":"\n# arranging the table \n# first by product in alphabetical order\n# then by \"region\" in reverse alphabetical order\nbudget %>%\n  arrange(product, desc(region))\nbudget %>%\n  mutate(region = factor(region, levels = c(\"North\", \"South\", \"East\", \"West\"))) %>%\n  filter(product == \"gadgets\") %>%\n  arrange(region)"},{"path":"wrangle.html","id":"mutate","chapter":"1 Data Wrangling","heading":"1.3.4 Mutate","text":"function mutate() allows add new columns change existing ones overwriting using syntax new_column = operation. can add one column mutate function separating columns comma. make new column, can use column definitions. example, creation profit uses column expenses, created .mutate() can also used conjunction functions Boolean operators. example, can add another column budget2 states whether profit returned year overwrite product variable factor. Just like used Boolean expressions filter, evaluate equation return TRUE FALSE depending whether observation meets criteria.can overwrite column giving new column name old column (see region product) . Make sure mean trying use old column value redefine .can also use case_when() specify values return, rather defaulting TRUE FALSE:Use recode values:combine different criteria:Just like filter(), mutate() incredibly powerful scope can create far beyond can cover book.","code":"\nbudget2 <- budget %>%\n  mutate(\n    sales = sales_2019 + sales_2020,\n    expenses = expenses_2019 + expenses_2020,\n    profit = sales - expenses,\n    region = paste(region, \"Office\")\n  )\nbudget2 <- budget2 %>%\n  mutate(profit_category = profit > 0,\n         product = as.factor(product))\nbudget3 <- budget2 %>%\n  mutate(profit_category = case_when(profit > 0 ~ \"PROFIT\",\n                                     profit < 0 ~ \"NO PROFIT\"))\n# create a column where people get a bonus if customer satisfaction was overall high or very high\n\nbonus <- budget3 %>%\n  mutate(bonus_2019 = case_when(satisfaction_2019 %in% c(\"very low\", \"low\", \"neutral\") ~ \"no bonus\",\n                                satisfaction_2019 %in% c(\"high\", \"very high\") ~ \"bonus\"))\n# new management takes over - people only get a bonus if customer satisfaction was overall high or very high AND if a profit was returned\n\nbonus2 <- budget3 %>%\n  mutate(bonus_2020 = case_when(satisfaction_2020 == \"high\" & \n                                  profit_category == \"PROFIT\" ~ \"bonus\",\n                                satisfaction_2020 == \"very high\" & \n                                  profit_category == \"PROFIT\" ~ \"bonus\",\n                                TRUE ~ \"No bonus\")) # set all other values to \"no bonus\""},{"path":"wrangle.html","id":"dplyr-summarise","chapter":"1 Data Wrangling","heading":"1.3.5 Summarise","text":"introduced summarise() function Chapter @ref({#summary-summarise}). applies summary functions entire table (groups, see next section).say want determine mean sales expenses, plus minimum maximum profit, region, product year. First, need reshape data like learned Chapter ??, column year one column sales expenses, instead separate columns year. also drop satisfaction data need analysis.Now can create summary statistics table.","code":"\nbudget4 <- budget %>%\n  select(-satisfaction_2019, -satisfaction_2020) %>%\n  pivot_longer(cols = sales_2019:expenses_2020,\n               names_to = c(\"type\", \"year\"),\n               names_sep = \"_\",\n               values_to = \"value\") %>%\n  pivot_wider(names_from = type,\n              values_from = value)\n\nhead(budget4) # check the format\nbudget4 %>%\n  summarise(\n    mean_sales = mean(sales),\n    mean_expenses = mean(expenses),\n    min_profit = min(expenses - sales),\n    max_profit = max(expenses - sales)\n  )"},{"path":"wrangle.html","id":"dplyr-groupby","chapter":"1 Data Wrangling","heading":"1.3.6 Group By","text":"introduced group_by() function Chapter ??. example, can break summary statistics year product.Note can use wrangling functions summary table, example:find maximum sales region?can also use group_by() combination functions. example, slice_max() returns top N rows, ordered specific variable.can combined group_by() return top sales region:","code":"\nyear_prod <- budget4 %>%\n  group_by(year, product) %>%\n  summarise(\n    mean_sales = mean(sales),\n    mean_expenses = mean(expenses),\n    min_profit = min(expenses - sales),\n    max_profit = max(expenses - sales)\n  ) %>%\n  ungroup()## `summarise()` has grouped output by 'year'. You can override using the `.groups` argument.\nyear_prod\n# arrange by maximum profit\nyear_prod %>%\n  arrange(desc(max_profit))\n\n# filter out gadgets\nyear_prod %>%\n  filter(product != \"gadgets\")budget3 %>%\n  group_by(region) %>%\n  summarise(max_sales = max(sales)budget3 %>%\n  group_by(region) %>%\n  summarise(max_sales = max(region)budget3 %>%\n  group_by(sales) %>%\n  summarise(max_sales = max(region)budget3 %>%\n  group_by(sales) %>%\n  summarise(max_sales = max(sales)\n# return top 3 sales\nbudget4 %>%\n  slice_max(n = 3, order_by = sales)\n# return top sale for each region\nbudget4 %>%\n  group_by(region) %>%\n  slice_max(n = 1, order_by = sales)"},{"path":"wrangle.html","id":"complications","chapter":"1 Data Wrangling","heading":"1.4 Complications","text":"","code":""},{"path":"wrangle.html","id":"rounding","chapter":"1 Data Wrangling","heading":"1.4.1 Rounding","text":"say want round values nearest pound. pattern uses across() function apply round() function columns mean_sales max_profit.compare table one Section 1.3.6, see 2019 gadgets mean sales rounded 881.5 882, mean expenses rounded 238.5 238. going !?may seem like mistake, R rounds .5 nearest even number, rather always , like probably taught school. prevents overestimation biases, since x.5 exactly halfway x x+1, reason always round .However, might throw monkey wrench systems. example, school policy round course marks x.5. solution define version round() (modified Andrew Landgraf's blog). Put hidden code block top script, clear warning changing way round() normally works. need understand function works, just use .run code, new section appear environment pane labelled \"Functions\". addition using functions packages, can also make . something going go detail course, useful know functionality exists.Now round() work expect.Just remove version want R go back original method. Remember define new round method script uses , run definition code use interactively. can check Environment pane see whether round listed \"Functions\".","code":"\nyear_prod %>%\n  mutate(across(.cols = mean_sales:max_profit, \n                .fns = round))\nround(0.5)\nround(1.5)## [1] 0\n## [1] 2\n#!!!!!! redefining round so 5s round up !!!!!! \nround <- function(x, digits = 0) {\n  posneg = sign(x)\n  z = abs(x)*10^digits\n  z = z + 0.5 + sqrt(.Machine$double.eps)\n  z = trunc(z)\n  z = z/10^digits\n  z*posneg\n}\nround(0.5)\nround(1.5)## [1] 1\n## [1] 2\n# remove new round() method\nrm(round)"},{"path":"wrangle.html","id":"missing-values","chapter":"1 Data Wrangling","heading":"1.4.2 Missing values","text":"control data, always best keep missing values empty cells rather denoting missingness word implausible number. used \"missing\" rather leaving cell empty, entire variable read character data, means able perform mathematical operations like calculating mean. use implausible number (0 999 common), risk values included calculations real numbers.However, often control data come us, run fix .","code":""},{"path":"wrangle.html","id":"bad-missing-values","chapter":"1 Data Wrangling","heading":"1.4.2.1 Bad missing values","text":"South region returned expenses (entered 0) North region returned sales data 2020 yet, someone entered \"missing\"?South data, can use ifelse() set value expenses 0 year 2020 region \"South\", otherwise use value expenses column (.e., change).Alternatively, can use case_when() convert expenses 2020 0. last line TRUE ~ expenses means default value retrieved expenses column, none previous criteria applied.case_when() function allows allows set multiple criteria, although using one non-default criterion . can useful, takes little practice.example creates label row. Notice label first row \"x < 2\", even though row also fits second criterion \"y < 4\". case_when() applies first match row, even criteria function also match row.North, need recode values \"missing\". Since character data, sales numeric data, result coerced character.using case_when(), first need convert sales column character, function little pickier let combine data types, since almost always means making mistake.Now, try compute mean sales, get error message result NA.","code":"\nmissing_bad <- budget4 %>%\n  mutate(expenses = ifelse(\n    test = year == 2020 & region == \"South\", \n    yes = 0,\n    no = expenses\n  ))\nmissing_bad <- budget4 %>%\n  mutate(expenses = case_when(\n    # set to 0 when year is 2020 and region is North\n    year == 2020 & region == \"South\" ~ 0, \n    # otherwise, set to the value in the expenses column\n    TRUE ~ expenses   \n  ))\ndata <- tibble(\n  x = 1:5,\n  y = 1:5\n)\n\ndata %>%\n  mutate(label = case_when(\n    x < 2           ~ \"x < 2\",\n    y < 4           ~ \"y < 4\",\n    x == 5 & y == 5 ~ \"both 5\",\n    TRUE            ~ \"default\"\n  ))\n# set sales values to \"missing\" for North 2020 rows\nmissing_bad <- missing_bad %>%\n  mutate(sales = ifelse(year == 2020 & region == \"North\", \n                        \"missing\", \n                        sales))\n\n# check structure of data, sales now character\nstr(missing_bad)## tibble [16 × 5] (S3: tbl_df/tbl/data.frame)\n##  $ region  : chr [1:16] \"North\" \"North\" \"North\" \"North\" ...\n##  $ product : chr [1:16] \"widgets\" \"widgets\" \"gadgets\" \"gadgets\" ...\n##  $ year    : chr [1:16] \"2019\" \"2020\" \"2019\" \"2020\" ...\n##  $ sales   : chr [1:16] \"2129\" \"missing\" \"723\" \"missing\" ...\n##  $ expenses: num [1:16] 822 -897 1037 1115 1004 ...\n# set sales values to \"missing\" for North 2020 rows\nmissing_bad <- missing_bad %>%\n  mutate(sales = as.character(sales),\n         sales = case_when(year == 2020 & region == \"North\" ~ \"missing\", \n                           TRUE ~ sales))\n# try to compute mean sales\nmissing_bad %>%\n  summarise(mean_sales = mean(sales))## Warning in mean.default(sales): argument is not numeric or logical: returning NA"},{"path":"wrangle.html","id":"convert-missing-values-to-na","chapter":"1 Data Wrangling","heading":"1.4.2.2 Convert missing values to NA","text":"set missing values NA, use either ifelse() case_when(). sales column converted character, also need transform back numeric.case_when() picky character types, need specify type NA using (specific NA data type). change NA_character_ NA code , get following error message:Technically, NA logical data type, functions picky combining data types coerce NA version compatible data type.Now, try calculate mean sales profits, get missing values summary value used one North 2020 sales values South 2020 expenses.","code":"\nmissing_data <- missing_bad %>%\n  mutate(\n    # set \"0\" values to NA using ifelse\n    expenses = ifelse(expenses == 0, NA, expenses),\n    # set \"missing\" values to NA using case_when\n    sales = case_when(sales == \"missing\" ~ NA_character_,\n                      TRUE ~ sales),\n    # convert to numeric\n    sales = as.numeric(sales)\n  )Error: Problem with `mutate()` column `sales`. ℹ `sales = case_when(sales == \"missing\" ~ NA, TRUE ~ sales)`. x must be a logical vector, not a character vector.\nmissing_data %>%\n  group_by(region) %>%\n  summarise(\n    mean_sales = mean(sales),\n    mean_expenses = mean(expenses),\n    min_profit = min(expenses - sales),\n    max_profit = max(expenses - sales),\n    .groups = \"drop\")"},{"path":"wrangle.html","id":"ignore-missing-values","chapter":"1 Data Wrangling","heading":"1.4.2.3 Ignore missing values","text":"NA basically means \"know\", sum 100 \"know\" \"know\", 100. However, calculating means, often want just ignore missing values. Set na.rm = TRUE summary function remove missing values calculating.","code":"\nmissing_data %>%\n  group_by(region) %>%\n  summarise(\n    mean_sales = mean(sales, na.rm = TRUE),\n    mean_expenses = mean(expenses, na.rm = TRUE),\n    min_profit = min(expenses - sales, na.rm = TRUE),\n    max_profit = max(expenses - sales, na.rm = TRUE),\n    .groups = \"drop\"\n  )"},{"path":"wrangle.html","id":"count-missing-values","chapter":"1 Data Wrangling","heading":"1.4.2.4 Count missing values","text":"want find many missing non-missing values column, use .na() function get logical vector whether value missing, use sum() count many values TRUE mean() calculate proportion TRUE values.","code":"\nmissing_data %>%\n  group_by(year, product) %>%\n  summarise(\n    n_valid = sum(!is.na(sales)),\n    n_missing = sum(is.na(sales)),\n    prop_missing = mean(is.na(sales)),\n    .groups = \"drop\"\n  )"},{"path":"wrangle.html","id":"omit-missing-values","chapter":"1 Data Wrangling","heading":"1.4.2.5 Omit missing values","text":"may also want remove rows missing values work complete datasets. drop_na() remove row missing observation. can use drop_na() entire dataset remove row missing value, can specify remove rows missing specific value.Missing data can quite difficult deal depending represented. always, amount coding expertise can make understanding structure idiosyncrasies data.","code":"\n# remove any rows with any missing values\ncomplete_data <- missing_data %>%\n  drop_na()\n\n# remove any rows that are missing a value for sales\ncomplete_sales <- missing_data %>%\n  drop_na(sales)"},{"path":"wrangle.html","id":"together-wrangle","chapter":"1 Data Wrangling","heading":"1.5 Exercises","text":"try exercises using dataset already encountered Chapter ?? can see much able data now.Save current Markdown, close , open new Rmd named \"survey_data_mad_skillz\".set-code chunk, load tidyverse, load dataset https://psyteachr.github.io/ads-v1/data/survey_data.csv object named survey_data.Use method choice review dataset familiarise structure.","code":"\n# from https://www.kaggle.com/kyanyoga/sample-sales-data\nlibrary(tidyverse)\nsurvey_data <- read_csv(\"https://psyteachr.github.io/ads-v1/data/survey_data.csv\")## Rows: 707 Columns: 7## ── Column specification ────────────────────────────────────────────────────────\n## Delimiter: \",\"\n## chr  (3): caller_id, employee_id, issue_category\n## dbl  (3): wait_time, call_time, satisfaction\n## dttm (1): call_start## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."},{"path":"wrangle.html","id":"creating-new-categories","chapter":"1 Data Wrangling","heading":"1.5.1 Creating new categories","text":"Employees 1-5 trained Michael employees 6-10 trained Dwight.Create new column named trainer lists trainer employee., calculate average satisfaction scores employees trained trainer visualise satisfaction scores whatever way think best.","code":"\nsurvey_data <- survey_data %>%\n  mutate(trainer = case_when(employee_id %in% c(\"E01\", \"E02\", \"E03\", \"E04\", \"E05\") ~ \"Michael\",\n                             employee_id %in% c(\"E06\", \"E07\", \"E08\", \"E09\", \"E10\") ~ \"Dwight\"))\n\n# mean satisfaction scores\nsurvey_data %>%\n  group_by(trainer) %>%\n  summarise(mean_satisfaction = mean(satisfaction))\n\n# possible visualisation \n\nggplot(survey_data, aes(x = satisfaction, fill = trainer)) +\n  geom_histogram(binwidth = 1, show.legend = FALSE, colour = \"black\") +\n  facet_wrap(~trainer) +\n  labs(title = \"Satisfaction scores by employee trainer\")"},{"path":"wrangle.html","id":"filter-by-calculated-score","chapter":"1 Data Wrangling","heading":"1.5.2 Filter by calculated score","text":"First, calculate average wait time store object named mean_wait. single value rather table.multiple ways achieve . create table pull single value, just calculate single value.Now create dataset named long_wait just contains data customers waited average wait time.Create visualisation shows many customers waited average wait time employee.","code":"\n# method 1 - tidyverse\nmean_wait <- survey_data %>%\n  summarise(mean_wait = mean(wait_time)) %>%\n  pull(mean_wait)\n\n# method 2 - base R\nmean_wait <- mean(survey_data$wait_time)\nlong_wait <- survey_data %>%\n  filter(wait_time > mean_wait)\nlong_wait %>%\n  ggplot(aes(x = employee_id)) +\n  geom_bar()"},{"path":"wrangle.html","id":"multiple-critera","chapter":"1 Data Wrangling","heading":"1.5.3 Multiple critera","text":"Now, add column survey_data named follow_up flags whether customer followed courtesy phone call. company short-staffed customers meet three following criteria followed-:wait time average callsTheir call time average categoryTheir satisfaction less three 3.quite complicated multiple ways achieve desired outcome. approaches may need functions covered previous chapters may need create intermediate objects.Call final object follow_data keep customer ID, employee ID, trainer, follow columns., write code stores answer single value, easily use inline coding.many customers need followed :total? calls employee 06? calls employees trained Michael calls employees trained Dwight `group_by %>% count() %>% filter() %>% pull()employee needs make largest number follow-courtesy calls? add ungroup() slice_max() along way.","code":"\n# this is one possible solution, there are many other valid approaches \n\n# calculate mean wait time across all calls\nmean_wait <- mean(survey_data$wait_time)\n\n# calculate mean call time for each category\nfollow_data <- survey_data %>%\n  group_by(issue_category) %>%\n  summarise(mean_call = mean(call_time)) %>%\n#then join it to the survey data  \n  left_join(survey_data, by = \"issue_category\") %>%\n# then add on the column\n  mutate(follow_up = case_when(wait_time > mean_wait & \n                               call_time > mean_call & \n                               satisfaction < 3 ~ \"yes\",\n                               TRUE ~ \"no\")) %>%\n  select(caller_id, employee_id, trainer, follow_up)\n# in total\nfollow_data %>%\n  group_by(follow_up) %>%\n  count()%>%\n  filter(follow_up == \"yes\") %>%\n  pull(n)\n\n# by employee 6\nfollow_data %>%\n  group_by(follow_up, employee_id) %>%\n  count() %>%\n  filter(employee_id == \"E06\",\n         follow_up == \"yes\") %>%\n  pull(n)\n\n# by michael\nfollow_data %>%\n  group_by(follow_up, trainer) %>%\n  count() %>%\n  filter(trainer == \"Michael\",\n         follow_up == \"yes\") %>%\n  pull(n)\n\n# by dwight\nfollow_data %>%\n  group_by(follow_up, trainer) %>%\n  count() %>%\n  filter(trainer == \"Dwight\",\n         follow_up == \"yes\") %>%\n  pull(n)\n\n# most follow-ups needed\nfollow_data %>%\n  group_by(follow_up, employee_id) %>%\n  count() %>%\n  ungroup() %>%\n  filter(follow_up == \"yes\") %>%\n  slice_max(n = 1, order_by = n) %>%\n  pull(employee_id)## [1] 120\n## [1] 16\n## [1] 65\n## [1] 55\n## [1] \"E02\""},{"path":"wrangle.html","id":"original-insight","chapter":"1 Data Wrangling","heading":"1.5.4 Original insight","text":"preparation final summative assessment, explore data provide one original insight .","code":""},{"path":"wrangle.html","id":"report","chapter":"1 Data Wrangling","heading":"1.5.5 Report","text":"Compile visually appealing reproducible report used target employees trainers extra training (depending mood , fire ). Use inline coding report numbers text. finished, post Rmd knitted html document teams learners can see approach.","code":""},{"path":"wrangle.html","id":"glossary-wrangle","chapter":"1 Data Wrangling","heading":"1.6 Glossary","text":"","code":""},{"path":"wrangle.html","id":"resources-wrangle","chapter":"1 Data Wrangling","heading":"1.7 Further resources","text":"Data transformation cheat sheetChapter 5: Data Transformation R Data ScienceChapter 19: Functions R Data ScienceIntroduction stringr","code":""}]
